# -*- coding: utf-8 -*-
"""
PD vs HC ì´ì§„ë¶„ë¥˜ íŒŒì´í”„ë¼ì¸ (AUC ìµœê³  ëª¨ë¸ ì„ ì • ë° ì¢…í•© ì•„í‹°íŒ©íŠ¸ ì €ì¥)
"""

# ==============================================================================
# 0. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
# ==============================================================================
import os, warnings
warnings.filterwarnings("ignore") # ë¶ˆí•„ìš”í•œ ê²½ê³  ë©”ì‹œì§€ ë¬´ì‹œ

# ë°ì´í„° ì²˜ë¦¬ ë° ì—°ì‚°
import numpy as np
import pandas as pd

# í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
import optuna

# ëª¨ë¸ í•´ì„ ë° í”¼ì²˜ ì¤‘ìš”ë„
import shap

# Scikit-learn: ëª¨ë¸ë§ ë° í‰ê°€ ê´€ë ¨ ë„êµ¬
from sklearn.model_selection import StratifiedGroupKFold, StratifiedKFold, train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.feature_selection import RFE, SequentialFeatureSelector
from sklearn.metrics import (
    roc_auc_score, f1_score, recall_score, precision_score, accuracy_score, make_scorer, confusion_matrix
)

# ë¶„ë¥˜ê¸° ëª¨ë¸ë“¤
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.neural_network import MLPClassifier
from sklearn.neighbors import KNeighborsClassifier
from lightgbm import LGBMClassifier
from xgboost import XGBClassifier
from catboost import CatBoostClassifier

# ìµœì¢… ì‚°ì¶œë¬¼ ì €ì¥
from joblib import dump

# ==============================================================================
# 1. ì „ì—­ ì„¤ì • ë° ìƒìˆ˜ ì •ì˜
# ==============================================================================
# Optuna ìµœì í™” ëª©í‘œ ì§€í‘œ ì„¤ì • ('auc' ë˜ëŠ” 'f1')
OBJECTIVE_METRIC = 'auc'
# Scikit-learnì˜ cross_val_scoreì—ì„œ ì‚¬ìš©í•  í‰ê°€ ì§€í‘œ ë¬¸ìì—´
OBJECTIVE_SCORER = 'roc_auc' if OBJECTIVE_METRIC == 'auc' else make_scorer(f1_score)

# ë°ì´í„° ë° ê²°ê³¼ë¬¼ ê²½ë¡œ ì„¤ì •
CSV_PATH = "severity_dataset_dropped_correlated_columns_modf.csv" # ì…ë ¥ ë°ì´í„° íŒŒì¼ ê²½ë¡œ
ARTIFACT_DIR = "pd_hc_binary" # ê²°ê³¼ë¬¼ì´ ì €ì¥ë  ë””ë ‰í† ë¦¬
os.makedirs(ARTIFACT_DIR, exist_ok=True) # ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±

# ì‹¤í—˜ ì¬í˜„ì„±ì„ ìœ„í•œ ì„¤ì •
RANDOM_STATE = 42 # ëª¨ë“  ëœë¤ ì—°ì‚°ì— ì‚¬ìš©í•  ì‹œë“œ ê°’
N_TRIALS = 20 # Optunaê°€ ê° ëª¨ë¸ë³„ë¡œ ì‹œë„í•  í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°í•©ì˜ ìˆ˜

# í”¼ì²˜ ì„ íƒ ì „ëµ ì„¤ì •
USE_RFE, RFE_N_FEATURES = True, 30 # RFE(ì¬ê·€ì  í”¼ì²˜ ì œê±°) ì‚¬ìš© ì—¬ë¶€ ë° ëª©í‘œ í”¼ì²˜ ìˆ˜
USE_RFA, RFA_N_FEATURES = True, 20 # SFS(ìˆœì°¨ì  í”¼ì²˜ ì„ íƒ, ì½”ë“œì—ì„œëŠ” RFAë¡œ ëª…ëª…) ì‚¬ìš© ì—¬ë¶€ ë° ëª©í‘œ í”¼ì²˜ ìˆ˜

# ì„ê³„ê°’ íŠœë‹ ê´€ë ¨ ì„¤ì •
TARGET_RECALL = 0.90 # ì¬í˜„ìœ¨ ëª©í‘œì¹˜ ì„ê³„ê°’ íŠœë‹ ì‹œ ì‚¬ìš©í•  íƒ€ê²Ÿ ì¬í˜„ìœ¨
HAND_THRESHOLD_DEFAULT = 0.50 # ì†(hand) ë‹¨ìœ„ ì˜ˆì¸¡ ì‹œ ì‚¬ìš©í•  ê¸°ë³¸ ì„ê³„ê°’ (í˜„ì¬ ì½”ë“œì—ì„œëŠ” ì§ì ‘ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ)

# íŠœë‹ ë° í‰ê°€ë¥¼ ì§„í–‰í•  ëª¨ë¸ ëª©ë¡
MODEL_LIST = [
    "LightGBM", "XGBoost", "CatBoost", "LogisticRegression", "RandomForest",
    "ExtraTrees", "GradientBoosting", "AdaBoost", "SVM", "GaussianNB", "MLP", "KNN"
]

# ==============================================================================
# 2. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì •ì˜ (ì£¼ë¡œ ì„ê³„ê°’ íŠœë‹ ê´€ë ¨)
# ==============================================================================

def noisyor_group_probs(groups, probs):
    """
    ë™ì¼í•œ ì‚¬ëŒ(group)ì—ê²Œì„œ ë‚˜ì˜¨ ì—¬ëŸ¬ ì˜ˆì¸¡ í™•ë¥ (probs)ì„ 'noisy-OR' ë°©ì‹ìœ¼ë¡œ ê²°í•©í•˜ì—¬
    ì‚¬ëŒ ë‹¨ìœ„ì˜ ë‹¨ì¼ ì˜ˆì¸¡ í™•ë¥ ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    (ì˜ˆ: í•œ ì‚¬ëŒì˜ ì™¼ì†, ì˜¤ë¥¸ì† ë°ì´í„° ì˜ˆì¸¡ ê²°ê³¼ë¥¼ í•©ì‚°)
    """
    df = pd.DataFrame({"g": groups, "p": probs})
    # í•œ ì‚¬ëŒì´ë¼ë„ 'yes'ì¼ í™•ë¥  = 1 - (ëª¨ë“  ì˜ˆì¸¡ì´ 'no'ì¼ í™•ë¥ ì˜ ê³±)
    agg = df.groupby("g")["p"].apply(lambda s: 1.0 - float(np.prod(1.0 - s.values)))
    return agg

def tune_threshold_noisyor(y_true_person, p_person, target_recall=0.90):
    """
    ì‚¬ëŒ ë‹¨ìœ„ ì˜ˆì¸¡ì—ì„œ, ëª©í‘œ ì¬í˜„ìœ¨(target_recall)ì„ ë§Œì¡±ì‹œí‚¤ë©´ì„œ
    F1 ì ìˆ˜ê°€ ê°€ì¥ ë†’ì€ ìµœì ì˜ ì„ê³„ê°’(threshold)ì„ ì°¾ìŠµë‹ˆë‹¤.
    """
    thresholds = np.linspace(0.01, 0.99, 99)
    best_meeting = None # ì¬í˜„ìœ¨ ëª©í‘œë¥¼ ë§Œì¡±í•˜ëŠ” í›„ë³´ ì¤‘ ìµœê³ 
    best_overall = {"thr": 0.5, "recall": 0.0, "f1": 0.0} # ì „ì²´ í›„ë³´ ì¤‘ F1 ìµœê³ 

    for t in thresholds:
        pred = (p_person >= t).astype(int)
        rec = recall_score(y_true_person, pred, zero_division=0)
        f1  = f1_score(y_true_person, pred, zero_division=0)

        # ì¬í˜„ìœ¨ ëª©í‘œë¥¼ ë‹¬ì„±í•œ ê²½ìš°
        if rec >= target_recall:
            if (best_meeting is None) or (f1 > best_meeting["f1"]):
                best_meeting = {"threshold": float(t), "recall": float(rec), "f1": float(f1)}
        
        # ì „ì²´ F1 ìµœê³  ê¸°ë¡ ê°±ì‹ 
        if f1 > best_overall["f1"]:
            best_overall = {"threshold": float(t), "recall": float(rec), "f1": float(f1)}
    
    # ëª©í‘œë¥¼ ë‹¬ì„±í•œ ì„ê³„ê°’ì´ ìˆìœ¼ë©´ ê·¸ê²ƒì„, ì—†ìœ¼ë©´ F1ì´ ê°€ì¥ ë†’ì•˜ë˜ ì„ê³„ê°’ì„ ì„ íƒ
    final_choice = best_meeting if best_meeting is not None else best_overall
    if "threshold" not in final_choice: final_choice["threshold"] = 0.5 # ì˜ˆì™¸ ì²˜ë¦¬
    return final_choice

def tune_threshold_youden(y_true_person, p_person):
    """
    Youden's J-index (ë¯¼ê°ë„ + íŠ¹ì´ë„ - 1)ë¥¼ ìµœëŒ€í™”í•˜ëŠ” ìµœì ì˜ ì„ê³„ê°’ì„ ì°¾ìŠµë‹ˆë‹¤.
    ì´ ì§€í‘œëŠ” ëª¨ë¸ì´ ì–‘ì„±ê³¼ ìŒì„±ì„ ì–¼ë§ˆë‚˜ ì˜ êµ¬ë¶„í•˜ëŠ”ì§€ ì¢…í•©ì ìœ¼ë¡œ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
    """
    thresholds = np.linspace(0.01, 0.99, 99)
    best = {"threshold": 0.5, "sensitivity": 0.0, "specificity": 0.0, "youden": -1.0}
    for t in thresholds:
        pred = (p_person >= t).astype(int)
        tn, fp, fn, tp = confusion_matrix(y_true_person, pred).ravel()
        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0.0 # ì¬í˜„ìœ¨ (Recall)
        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0
        youden = sensitivity + specificity - 1
        if youden > best["youden"]:
            best = {
                "threshold": float(t), "sensitivity": float(sensitivity),
                "specificity": float(specificity), "youden": float(youden)
            }
    return best

def tune_threshold_by_metric(y_true, y_prob, metric_func, metric_name):
    """
    F1, Accuracy ë“± íŠ¹ì • í‰ê°€ ì§€í‘œ(metric)ë¥¼ ìµœëŒ€í™”í•˜ëŠ” ë²”ìš© ì„ê³„ê°’ íŠœë‹ í•¨ìˆ˜ì…ë‹ˆë‹¤.
    """
    thresholds = np.linspace(0.01, 0.99, 99)
    best_score = -1
    best_thr = 0.5
    for thr in thresholds:
        y_pred = (y_prob >= thr).astype(int)
        
        # í‰ê°€ ì§€í‘œì— ë”°ë¼ ì¸ì ì‚¬ìš©ì„ ë‹¤ë¥´ê²Œ í•¨
        if metric_name == "accuracy":
            score = metric_func(y_true, y_pred)
        else:
            score = metric_func(y_true, y_pred, zero_division=0)
            
        if score > best_score:
            best_score = score
            best_thr = thr
            
    return {"threshold": float(best_thr), metric_name: float(best_score)}

# ==============================================================================
# 3. ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬, ë¶„í• 
# ==============================================================================
# CSV íŒŒì¼ ë¡œë“œ
df = pd.read_csv(CSV_PATH)

# íƒ€ê²Ÿ ë³€ìˆ˜(y) ìƒì„±: 'yes' -> 1, 'no' -> 0
y = df["diagnosed"].str.lower().map({"yes": 1, "no": 0}).astype(int)
# ê·¸ë£¹ ë³€ìˆ˜(groups) ìƒì„±: ë°ì´í„°ê°€ ì–´ë–¤ ì‚¬ëŒ/íŒŒì¼ì—ì„œ ì™”ëŠ”ì§€ ì‹ë³„
groups = df["filename"].astype(str)

# ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ë“¤(ì¸ë±ìŠ¤, íƒ€ê²Ÿ, ê·¸ë£¹ ì •ë³´ ë“±)ì„ í”¼ì²˜ì—ì„œ ì œì™¸
drop_cols = ["Unnamed: 0"] if "Unnamed: 0" in df.columns else []
for c in ["diagnosed", "Rating", "filename"]:
    if c in df.columns: drop_cols.append(c)
X_all = df.drop(columns=drop_cols, errors="ignore")

# í”¼ì²˜ë¥¼ ë²”ì£¼í˜•(categorical)ê³¼ ìˆ˜ì¹˜í˜•(numerical)ìœ¼ë¡œ ë¶„ë¦¬
cat_cols = [c for c in X_all.columns if X_all[c].dtype == "object"]
num_cols = [c for c in X_all.columns if c not in cat_cols]

# Hold-out: ì „ì²´ ë°ì´í„°ë¥¼ í•™ìŠµ(Train)ìš©ê³¼ í…ŒìŠ¤íŠ¸(Test)ìš©ìœ¼ë¡œ ë¶„í•  (80:20)
# stratify=y : ì›ë³¸ ë°ì´í„°ì˜ 0/1 ë¹„ìœ¨ì„ í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œë„ ë™ì¼í•˜ê²Œ ìœ ì§€
X_train, X_test, y_train, y_test, groups_train, groups_test = train_test_split(
    X_all, y, groups, test_size=0.2, random_state=RANDOM_STATE, stratify=y
)
print(f"[INFO] Train size={X_train.shape[0]}, Test size={X_test.shape[0]}")

# ==============================================================================
# 4. SHAP ê¸°ë°˜ í”¼ì²˜ ì„ íƒ (Feature Selection)
# ==============================================================================
# 1. SHAP ì¤‘ìš”ë„ ê³„ì‚°ì„ ìœ„í•œ ê¸°ë³¸ ëª¨ë¸ íŒŒì´í”„ë¼ì¸ ìƒì„±
#    - ìˆ˜ì¹˜í˜• í”¼ì²˜: StandardScalerë¡œ ìŠ¤ì¼€ì¼ë§
#    - ë²”ì£¼í˜• í”¼ì²˜: OneHotEncoderë¡œ ë³€í™˜
pre_all = ColumnTransformer(transformers=[("num", StandardScaler(), num_cols), 
                                          ("cat", OneHotEncoder(handle_unknown="ignore", sparse_output=False), 
                                           cat_cols)], remainder="drop")
base_model_fs = LGBMClassifier(random_state=RANDOM_STATE, class_weight="balanced", verbose=-1)
pipe_base = Pipeline(steps=[("preprocessor", pre_all), ("classifier", base_model_fs)])
pipe_base.fit(X_train, y_train)

# 2. SHAP ê°’ ê³„ì‚°
feature_names = pipe_base.named_steps["preprocessor"].get_feature_names_out() # ì „ì²˜ë¦¬ í›„ í”¼ì²˜ ì´ë¦„ë“¤
X_proc = pipe_base.named_steps["preprocessor"].transform(X_train) # í•™ìŠµ ë°ì´í„° ì „ì²˜ë¦¬
explainer = shap.TreeExplainer(pipe_base.named_steps["classifier"]) # SHAP ì„¤ëª…ê°ì²´ ìƒì„±
shap_values = explainer.shap_values(X_proc) # SHAP ê°’ ê³„ì‚°
if isinstance(shap_values, list): shap_values = shap_values[1] # ì´ì§„ ë¶„ë¥˜ì˜ ê²½ìš° ì–‘ì„± í´ë˜ìŠ¤(1)ì— ëŒ€í•œ SHAP ê°’ë§Œ ì‚¬ìš©
shap_importance = np.abs(shap_values).mean(axis=0) # ê° í”¼ì²˜ì˜ í‰ê· ì ì¸ ì˜í–¥ë ¥(ì ˆëŒ€ê°’ ê¸°ì¤€) ê³„ì‚°

# 3. SHAP ì¤‘ìš”ë„ ê¸°ë°˜ 1ì°¨ í”¼ì²˜ ì„ íƒ
feat_importance = pd.DataFrame({"feature": feature_names, "importance": shap_importance})
feat_importance = feat_importance.sort_values('importance', ascending=False).reset_index(drop=True)
median_val = feat_importance['importance'].median() # ì¤‘ìš”ë„ì˜ ì¤‘ì•™ê°’ ê³„ì‚°
feat_importance['selected_by_shap'] = feat_importance['importance'] >= median_val # ì¤‘ì•™ê°’ ì´ìƒì¸ í”¼ì²˜ë§Œ ì„ íƒ
shap_csv_path = os.path.join(ARTIFACT_DIR, 'shap_features.csv')
feat_importance.to_csv(shap_csv_path, index=False)
print(f"[INFO] Saved SHAP features â†’ {shap_csv_path}")

selected_feat = feat_importance.loc[feat_importance['selected_by_shap'], 'feature'].tolist()

# 4. (ì„ íƒì ) RFEë¥¼ ì´ìš©í•œ 2ì°¨ í”¼ì²˜ ì„ íƒ
if USE_RFE and len(selected_feat) > RFE_N_FEATURES:
    rfe_est = LGBMClassifier(random_state=RANDOM_STATE, class_weight="balanced", verbose=-1)
    rfe = RFE(estimator=rfe_est, n_features_to_select=RFE_N_FEATURES)
    idx_sel = [list(feature_names).index(f) for f in selected_feat] # ì„ íƒëœ í”¼ì²˜ë“¤ì˜ ì¸ë±ìŠ¤
    rfe.fit(X_proc[:, idx_sel], y_train) # RFE ì‹¤í–‰
    selected_feat = [f for f, keep in zip(selected_feat, rfe.support_) if keep] # RFEê°€ ì„ íƒí•œ í”¼ì²˜ë§Œ ë‚¨ê¹€

# 5. (ì„ íƒì ) SFS/RFAë¥¼ ì´ìš©í•œ 3ì°¨ í”¼ì²˜ ì„ íƒ
if USE_RFA and len(selected_feat) > RFA_N_FEATURES:
    rfa_est = LGBMClassifier(random_state=RANDOM_STATE, class_weight="balanced", verbose=-1)
    cv_inner = StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)
    sfs = SequentialFeatureSelector(rfa_est, n_features_to_select=RFA_N_FEATURES, direction="forward", scoring="roc_auc", cv=cv_inner, n_jobs=-1)
    idx_sel = [list(feature_names).index(f) for f in selected_feat]
    sfs.fit(X_proc[:, idx_sel], y_train) # SFS ì‹¤í–‰
    selected_feat = [f for f, keep in zip(selected_feat, sfs.get_support()) if keep] # SFSê°€ ì„ íƒí•œ í”¼ì²˜ë§Œ ë‚¨ê¹€

print(f"[INFO] ìµœì¢… ì„ íƒëœ feature ìˆ˜: {len(selected_feat)}")

# ìµœì¢… ì„ íƒëœ í”¼ì²˜ ì´ë¦„ë“¤ì„ ì›ë˜ì˜ ì»¬ëŸ¼ ì´ë¦„ìœ¼ë¡œ ë³µì›
raw_num_selected, raw_cat_selected = [], []
for f in selected_feat:
    if f.startswith("num__"):
        raw_num_selected.append(f.split("num__")[-1])
    elif f.startswith("cat__"):
        col = f.split("cat__")[-1].split("_")[0]
        if col not in raw_cat_selected: raw_cat_selected.append(col)
raw_features = raw_num_selected + raw_cat_selected
print(f"[INFO] ì›ì‹œ ì…ë ¥ ì»¬ëŸ¼ ìˆ˜: {len(raw_features)} (num={len(raw_num_selected)}, cat={len(raw_cat_selected)})")

# ì„ íƒëœ í”¼ì²˜ë“¤ë§Œìœ¼ë¡œ êµ¬ì„±ëœ ìƒˆë¡œìš´ ì „ì²˜ë¦¬ê¸°(Preprocessor)ë¥¼ ë§Œë“œëŠ” í•¨ìˆ˜
def make_preprocessor_selected():
    transformers = []
    if len(raw_num_selected) > 0: transformers.append(("num", StandardScaler(), raw_num_selected))
    if len(raw_cat_selected) > 0: transformers.append(("cat", OneHotEncoder(handle_unknown="ignore", sparse_output=False), raw_cat_selected))
    # ë§Œì•½ ì„ íƒëœ í”¼ì²˜ê°€ í•˜ë‚˜ë„ ì—†ì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ ì˜ˆì™¸ì²˜ë¦¬
    if not transformers: transformers.append(("num", StandardScaler(), []))
    return ColumnTransformer(transformers=transformers, remainder="drop")

# ==============================================================================
# 5. Optunaë¥¼ ì´ìš©í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
# ==============================================================================
def build_model(trial, model_name):
    if model_name == "LightGBM":
        return LGBMClassifier(
            n_estimators=trial.suggest_int("n_estimators", 200, 800),
            learning_rate=trial.suggest_float("learning_rate", 0.01, 0.2),
            num_leaves=trial.suggest_int("num_leaves", 15, 63),
            subsample=trial.suggest_float("subsample", 0.7, 1.0),
            colsample_bytree=trial.suggest_float("colsample_bytree", 0.7, 1.0),
            random_state=RANDOM_STATE, class_weight="balanced", verbose=-1
        )
    elif model_name == "XGBoost":
        return XGBClassifier(
            n_estimators=trial.suggest_int("n_estimators", 200, 800),
            learning_rate=trial.suggest_float("learning_rate", 0.01, 0.2),
            max_depth=trial.suggest_int("max_depth", 3, 8),
            subsample=trial.suggest_float("subsample", 0.7, 1.0),
            colsample_bytree=trial.suggest_float("colsample_bytree", 0.7, 1.0),
            random_state=RANDOM_STATE, use_label_encoder=False, eval_metric="logloss", verbosity=0
        )
    elif model_name == "RandomForest":
        return RandomForestClassifier(
            n_estimators=trial.suggest_int("n_estimators", 100, 500),
            max_depth=trial.suggest_int("max_depth", 3, 20),
            random_state=RANDOM_STATE, class_weight="balanced"
        )
    elif model_name == "AdaBoost":
        return AdaBoostClassifier(
            n_estimators=trial.suggest_int("n_estimators", 100, 500),
            learning_rate=trial.suggest_float("learning_rate", 0.01, 0.5),
            random_state=RANDOM_STATE
        )
    elif model_name == "SVM":
        return SVC(
            C=trial.suggest_float("C", 0.1, 10.0, log=True),
            gamma=trial.suggest_float("gamma", 1e-4, 1e-1, log=True),
            kernel="rbf", probability=True, class_weight="balanced", random_state=RANDOM_STATE
        )
    elif model_name == "MLP":
        return MLPClassifier(
            hidden_layer_sizes=(trial.suggest_int("layer1", 32, 128),
                                trial.suggest_int("layer2", 16, 64)),
            max_iter=500, random_state=RANDOM_STATE
        )
    elif model_name == "KNN":
        return KNeighborsClassifier(n_neighbors=trial.suggest_int("n_neighbors", 3, 15))
    elif model_name == "ExtraTrees":
        return ExtraTreesClassifier(
            n_estimators=trial.suggest_int("n_estimators", 100, 500),
            random_state=RANDOM_STATE, class_weight="balanced"
        )
    elif model_name == "GradientBoosting":
        return GradientBoostingClassifier(
            n_estimators=trial.suggest_int("n_estimators", 100, 500),
            learning_rate=trial.suggest_float("learning_rate", 0.01, 0.2),
            random_state=RANDOM_STATE
        )
    elif model_name == "CatBoost":
        return CatBoostClassifier(
            iterations=trial.suggest_int("iterations", 200, 800),
            learning_rate=trial.suggest_float("learning_rate", 0.01, 0.2),
            depth=trial.suggest_int("depth", 4, 10),
            verbose=0, random_state=RANDOM_STATE
        )
    elif model_name == "LogisticRegression":
        return LogisticRegression(max_iter=500, class_weight="balanced", solver="liblinear")
    elif model_name == "GaussianNB":
        return GaussianNB()
    else:
        raise ValueError(model_name)

def objective(trial, model_name):
    """Optunaì˜ ê° trialì—ì„œ í˜¸ì¶œë  ëª©ì  í•¨ìˆ˜ì…ë‹ˆë‹¤. ì œì•ˆëœ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ ëª¨ë¸ì„ ë§Œë“¤ê³  êµì°¨ê²€ì¦ ì ìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        model = build_model(trial, model_name)
        pre_sel = make_preprocessor_selected() # ì„ íƒëœ í”¼ì²˜ìš© ì „ì²˜ë¦¬ê¸°
        pipeline = Pipeline(steps=[("preprocessor", pre_sel), ("classifier", model)])
        
        # StratifiedGroupKFold: ë™ì¼í•œ ì‚¬ëŒ(group)ì˜ ë°ì´í„°ê°€ train/validation foldì— ë™ì‹œì— ë“¤ì–´ê°€ì§€ ì•Šë„ë¡ ë¶„í• 
        cv = StratifiedGroupKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)
        scores = cross_val_score(
            pipeline, X_train, y_train, cv=cv, groups=groups_train,
            scoring=OBJECTIVE_SCORER,
            error_score='raise' # ì—ëŸ¬ ë°œìƒ ì‹œ ì¦‰ì‹œ ì¤‘ë‹¨
        )
        return scores.mean() # 3-fold êµì°¨ ê²€ì¦ ì ìˆ˜ì˜ í‰ê· ì„ ë°˜í™˜
    except Exception as e:
        print(f"ERROR in objective function with model: {model_name}, Error: {e}")
        raise optuna.exceptions.TrialPruned() # ì—ëŸ¬ ë°œìƒ ì‹œ í•´ë‹¹ trialì„ ì¤‘ë‹¨

# --- Optuna ì‹¤í–‰ ë£¨í”„ ---
optuna_rows, best_models, best_params_by_model = [], {}, {}

for model_name in MODEL_LIST:
    print(f"\n[Optuna] Optimizing {model_name} ...")
    study = optuna.create_study(direction="maximize") # ëª©í‘œ ì ìˆ˜(AUC)ë¥¼ ìµœëŒ€í™”í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ íƒìƒ‰
    study.optimize(lambda trial: objective(trial, model_name), n_trials=N_TRIALS) # N_TRIALS ë§Œí¼ ìµœì í™” ì‹¤í–‰
    
    # ìµœì í™” ê²°ê³¼ ì €ì¥
    best_params = study.best_params
    best_score = study.best_value
    print(f"[Optuna] Best {model_name} {OBJECTIVE_METRIC.upper()}={best_score:.3f}, params={best_params}")
    optuna_rows.append({"model": model_name, "objective": OBJECTIVE_METRIC, "best_objective": best_score, "best_params": best_params})
    best_params_by_model[model_name] = best_params
    
    # ì°¾ì€ ìµœì  íŒŒë¼ë¯¸í„°ë¡œ ëª¨ë¸ì„ ë‹¤ì‹œ ë§Œë“¤ì–´ í•™ìŠµ ë°ì´í„° ì „ì²´ë¡œ í•™ìŠµì‹œí‚¨ í›„ ì €ì¥
    final_model = build_model(optuna.trial.FixedTrial(best_params), model_name)
    pre_sel = make_preprocessor_selected()
    pipe = Pipeline(steps=[("preprocessor", pre_sel), ("classifier", final_model)])
    pipe.fit(X_train, y_train)
    best_models[model_name] = pipe

# Optuna íŠœë‹ ê²°ê³¼ ìš”ì•½ë³¸ì„ CSV íŒŒì¼ë¡œ ì €ì¥
pd.DataFrame(optuna_rows).to_csv(os.path.join(ARTIFACT_DIR, "optuna_results.csv"), index=False)


# ==============================================================================
# 6. Hold-out Test: ìµœì í™”ëœ ëª¨ë“  ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ìµœì¢… í‰ê°€
# ==============================================================================
test_rows = []
per_model_test_preds = {}
for model_name, pipe in best_models.items():
    y_prob = pipe.predict_proba(X_test)[:, 1] # ì–‘ì„±(1) í´ë˜ìŠ¤ì— ëŒ€í•œ ì˜ˆì¸¡ í™•ë¥ 
    y_pred = pipe.predict(X_test) # ê¸°ë³¸ ì„ê³„ê°’(0.5) ê¸°ì¤€ ì˜ˆì¸¡ ê²°ê³¼
    
    # ê°ì¢… ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
    test_rows.append({
        "model": model_name, "AUC": roc_auc_score(y_test, y_prob),
        "F1": f1_score(y_test, y_pred), "Recall": recall_score(y_test, y_pred),
        "Precision": precision_score(y_test, y_pred), "Accuracy": accuracy_score(y_test, y_pred)
    })
    per_model_test_preds[model_name] = (y_prob, y_pred)

# í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ AUC ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬í•˜ì—¬ CSVë¡œ ì €ì¥
test_df = pd.DataFrame(test_rows).sort_values("AUC", ascending=False)
test_df.to_csv(os.path.join(ARTIFACT_DIR, "test_results.csv"), index=False)
print(f"[INFO] Saved ALL model hold-out test results to {os.path.join(ARTIFACT_DIR, 'test_results.csv')}")

# ëª¨ë¸ë³„ ì„±ëŠ¥ ì§€í‘œë¥¼ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ì €ì¥
holdout_metrics_map = {row['model']: {'AUC': float(row['AUC']), 'F1': float(row['F1']), 'Recall': float(row['Recall']), 'Precision': float(row['Precision']), 'Accuracy': float(row['Accuracy'])} for _, row in test_df.iterrows()}


# ==============================================================================
# 7. ìµœì¢… ëª¨ë¸ ì„ ì • ë° ì„ê³„ê°’ íŠœë‹, ì‚°ì¶œë¬¼ ì €ì¥
# ==============================================================================
# ìŠ¹ì ê²°ì •: í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ AUC ê°’ì´ ê°€ì¥ ë†’ì€ ëª¨ë¸
best_model_name = test_df.loc[test_df["AUC"].idxmax(), "model"]
print("-" * 50)
print(f"ğŸ† [WINNER] Best Model by AUC: {best_model_name} (AUC = {test_df.iloc[0]['AUC']:.4f})")
print("-" * 50)

# --- ìµœê³  ëª¨ë¸ì— ëŒ€í•œ ì‚¬ëŒ ë‹¨ìœ„ ì„ê³„ê°’ íŠœë‹ ---
# 1. ì‚¬ëŒ ë‹¨ìœ„ ì˜ˆì¸¡ì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„
y_prob_test, _ = per_model_test_preds[best_model_name]
y_true_person = pd.Series(y_test.values, index=groups_test).groupby(level=0).max()
p_person = noisyor_group_probs(groups_test.values, y_prob_test)

# 2. ë‹¤ì–‘í•œ ì „ëµìœ¼ë¡œ ìµœì  ì„ê³„ê°’ íƒìƒ‰
tuned_recall = tune_threshold_noisyor(y_true_person.values, p_person.values, target_recall=TARGET_RECALL)
tuned_youden = tune_threshold_youden(y_true_person.values, p_person.values)
tuned_f1 = tune_threshold_by_metric(y_true_person.values, p_person.values, f1_score, "f1")
tuned_accuracy = tune_threshold_by_metric(y_true_person.values, p_person.values, accuracy_score, "accuracy")

# íŠœë‹ ê²°ê³¼ ì¶œë ¥
print(f"[TUNE-Recall]   {best_model_name}: thr={tuned_recall['threshold']:.4f}, recall={tuned_recall['recall']:.3f}, f1={tuned_recall['f1']:.3f}")
print(f"[TUNE-Youden]    {best_model_name}: thr={tuned_youden['threshold']:.4f}, sens={tuned_youden['sensitivity']:.3f}, spec={tuned_youden['specificity']:.3f}, J={tuned_youden['youden']:.3f}")
print(f"[TUNE-F1]        {best_model_name}: thr={tuned_f1['threshold']:.4f}, f1={tuned_f1['f1']:.3f}")
print(f"[TUNE-Accuracy] {best_model_name}: thr={tuned_accuracy['threshold']:.4f}, accuracy={tuned_accuracy['accuracy']:.3f}")

# --- ìµœì¢… ëª¨ë¸ì„ ì „ì²´ ë°ì´í„°ë¡œ ì¬í•™ìŠµ ---
params = best_params_by_model[best_model_name]
model = build_model(optuna.trial.FixedTrial(params), best_model_name)
pre_sel_full = make_preprocessor_selected()
pipe_full = Pipeline(steps=[("preprocessor", pre_sel_full), ("classifier", model)])
pipe_full.fit(X_all, y) # ì „ì²´ ë°ì´í„°(X_all, y)ë¡œ ìµœì¢… í•™ìŠµ

# --- ìµœì¢… ì‚°ì¶œë¬¼(Artifact) ìƒì„± ---
# ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„œ í•„ìš”í•œ ëª¨ë“  ì •ë³´ë¥¼ í•˜ë‚˜ì˜ ë”•ì…”ë„ˆë¦¬ë¡œ ë¬¶ìŒ
artifact = {
    "pipeline": pipe_full, # ì „ì²´ ë°ì´í„°ë¡œ ì¬í•™ìŠµëœ ìµœì¢… ëª¨ë¸ íŒŒì´í”„ë¼ì¸
    "model_name": best_model_name, # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ì˜ ì´ë¦„
    "selected_features": selected_feat, # ì „ì²˜ë¦¬ í›„ ì‚¬ìš©ëœ í”¼ì²˜ ì´ë¦„ ëª©ë¡
    "raw_features": raw_features, # ì›ë³¸ ë°ì´í„°ì—ì„œ ì‚¬ìš©ëœ ì»¬ëŸ¼ ì´ë¦„ ëª©ë¡
    "person_threshold": float(tuned_youden["threshold"]), # ê¸°ë³¸ìœ¼ë¡œ ì‚¬ìš©í•  ì‚¬ëŒ ë‹¨ìœ„ ì„ê³„ê°’ (Youden's Index ê¸°ì¤€)
    "hand_threshold": float(HAND_THRESHOLD_DEFAULT),
    "threshold_strategy": "youden", # ê¸°ë³¸ ì„ê³„ê°’ ì„ íƒ ì „ëµ
    "metrics_all": { # ëª¨ë“  ì„±ëŠ¥ ì§€í‘œ ë° ì„ê³„ê°’ íŠœë‹ ê²°ê³¼ ì €ì¥
        "holdout_test": holdout_metrics_map[best_model_name],
        "recall": tuned_recall,
        "youden": tuned_youden,
        "f1": tuned_f1,
        "accuracy": tuned_accuracy
    }
}

# ìµœì¢… ì•„í‹°íŒ©íŠ¸ë¥¼ joblib íŒŒì¼ë¡œ ì €ì¥
save_path = os.path.join(ARTIFACT_DIR, f"best_pipeline_auc_{best_model_name}.joblib")
dump(artifact, save_path)
print(f"\n[SUCCESS] ìµœì¢… ì•„í‹°íŒ©íŠ¸ ì €ì¥ ì™„ë£Œ â†’ {save_path}")
print("[DONE] Training + Threshold tuning + Artifact export complete.")