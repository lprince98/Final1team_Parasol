
import os, time, argparse, datetime as dt
import numpy as np
import pandas as pd
import cv2 as cv

# ---------------- feature_extraction ê°€ì ¸ì˜¤ê¸° + ì „ì—­ ì‹¬ë³¼ í•«í”½ìŠ¤ ----------------
from feature_extraction import get_final_features, distance
import feature_extraction as fe  # ëª¨ë“ˆ ê°ì²´

# iqr ë¶€ì¬ í•«í”½ìŠ¤ (NaN-safe)
if not hasattr(fe, "iqr"):
    def iqr(a):
        import numpy as _np
        a = _np.asarray(a, dtype=float)
        if a.size == 0:
            return float("nan")
        q75 = _np.nanpercentile(a, 75)
        q25 = _np.nanpercentile(a, 25)
        return float(q75 - q25)
    fe.iqr = iqr

# scikit-learn ì‹¬ë³¼ ì£¼ì… (LinearRegression, r2_score, PolynomialFeatures)
try:
    from sklearn.linear_model import LinearRegression as _LR
    from sklearn.metrics import r2_score as _r2
    try:
        from sklearn.preprocessing import PolynomialFeatures as _PF
    except Exception:
        _PF = None
except Exception:
    _LR = _r2 = _PF = None

if not hasattr(fe, "LinearRegression"):
    if _LR is None:
        raise SystemExit(
            "scikit-learnì´ í•„ìš”í•©ë‹ˆë‹¤. í™œì„± venvì—ì„œ\n"
            "  pip install scikit-learn\n"
            "ì„¤ì¹˜ í›„ ë‹¤ì‹œ ì‹¤í–‰í•´ ì£¼ì„¸ìš”."
        )
    fe.LinearRegression = _LR
if not hasattr(fe, "r2_score") and _r2 is not None:
    fe.r2_score = _r2
if _PF is not None and not hasattr(fe, "PolynomialFeatures"):
    fe.PolynomialFeatures = _PF
# ---------------------------------------------------------------------------

# MediaPipe
import mediapipe as mp
Hands = mp.solutions.hands.Hands
HAND_CONNECTIONS = mp.solutions.hands.HAND_CONNECTIONS
draw = mp.solutions.drawing_utils
from mediapipe.framework.formats import landmark_pb2

# Pillow(í•œê¸€)
try:
    from PIL import ImageFont, ImageDraw, Image
except Exception:
    ImageFont = ImageDraw = Image = None

# ----------------- ìœ í‹¸ -----------------
def ensure_dir(p): os.makedirs(p, exist_ok=True); return p
def now_tag(): return dt.datetime.now().strftime("%Y%m%d_%H%M%S")

def angle_deg(ax, ay, bx, by):
    dot = ax*bx + ay*by
    na = np.hypot(ax, ay); nb = np.hypot(bx, by)
    if na == 0 or nb == 0: return -1.0
    c = np.clip(dot/(na*nb), -1.0, 1.0)
    return float(np.degrees(np.arccos(c)))

def write_landmarks_csv(outdir, tag, hand_label, frames):
    rows = []
    for i, lm in enumerate(frames):
        row = {"frame": i, "hand": hand_label.upper()}
        if lm is None:
            for j in range(21):
                row[f"x_{j}"]=np.nan; row[f"y_{j}"]=np.nan; row[f"z_{j}"]=np.nan
        else:
            for j, l in enumerate(lm):
                row[f"x_{j}"]=l.x; row[f"y_{j}"]=l.y; row[f"z_{j}"]=l.z
        rows.append(row)
    pd.DataFrame(rows).to_csv(os.path.join(outdir, f"landmarks_{tag}_{hand_label.upper()}.csv"), index=False)

def collect_timeseries(session_landmarks, frame_size, duration_s):
    w, h = frame_size
    per_hand = {}

    for hand, frames in session_landmarks.items():
        D_raw, W_raw = [], []

        for lm in frames:
            if lm is None:
                D_raw.append(np.nan)  # ğŸ‘ˆ NaN ê¸°ë¡
                W_raw.append((np.nan, np.nan))
                continue

            w_lm, cmc, th, idx = lm[0], lm[1], lm[4], lm[8]
            wx, wy = int(w_lm.x * w), int(w_lm.y * h)
            tx, ty = int(th.x * w), int(th.y * h)
            ix, iy = int(idx.x * w), int(idx.y * h)

            ang = angle_deg(tx - wx, ty - wy, ix - wx, iy - wy)
            D_raw.append(ang)

            cmx, cmy = int(cmc.x * w), int(cmc.y * h)
            wnorm = distance(wx, wy, cmx, cmy) or np.nan
            W_raw.append((wx / wnorm, wy / wnorm) if not np.isnan(wnorm) else (np.nan, np.nan))

        # === NaN ë³´ê°„ ì²˜ë¦¬ ===
        df_tmp = pd.DataFrame({
            "D_raw": D_raw,
            "W_raw_x": [w[0] for w in W_raw],
            "W_raw_y": [w[1] for w in W_raw]
        })
        df_tmp = df_tmp.interpolate(limit_direction="both")  # ì•ë’¤ ê°’ìœ¼ë¡œ ë³´ê°„

        # ë‹¤ì‹œ numpyë¡œ ë³€í™˜
        D_raw = df_tmp["D_raw"].to_numpy()
        W_raw = list(zip(df_tmp["W_raw_x"], df_tmp["W_raw_y"]))

        per_hand[hand] = {
            "D_raw": D_raw,
            "W_raw": W_raw,
            "num_frames": len(frames),
            "duration": float(duration_s)
        }

    return per_hand

# -------------- í•œê¸€ í…ìŠ¤íŠ¸ --------------
def _auto_korean_font():
    cands = [
        r"C:\Windows\Fonts\malgun.ttf", r"C:\Windows\Fonts\malgunbd.ttf",
        r"C:\Windows\Fonts\NanumGothic.ttf", r"C:\Windows\Fonts\gulim.ttc",
        "/System/Library/Fonts/AppleSDGothicNeo.ttc",
        "/usr/share/fonts/truetype/nanum/NanumGothic.ttf",
    ]
    for p in cands:
        if os.path.exists(p): return p
    return None

def put_kr(img_bgr, text, org, font_path=None, font_size=26,
           color=(255,255,255), stroke_color=(0,0,0), stroke_width=2):
    if ImageFont is None:
        cv.putText(img_bgr, text, org, cv.FONT_HERSHEY_SIMPLEX, 0.8, color, 2, cv.LINE_AA)
        return img_bgr
    if not font_path or not os.path.exists(font_path):
        font_path = _auto_korean_font()
    try:
        font = ImageFont.truetype(font_path, font_size) if font_path else None
    except Exception:
        font = None
    if font is None:
        cv.putText(img_bgr, text, org, cv.FONT_HERSHEY_SIMPLEX, 0.8, color, 2, cv.LINE_AA)
        return img_bgr

    def bgr2rgb(c): return (int(c[2]), int(c[1]), int(c[0]))
    img_rgb = cv.cvtColor(img_bgr, cv.COLOR_BGR2RGB)
    pil_img = Image.fromarray(img_rgb); draw_pil = ImageDraw.Draw(pil_img)
    if stroke_width>0:
        draw_pil.text(org, text, font=font, fill=bgr2rgb(stroke_color),
                      stroke_width=stroke_width, stroke_fill=bgr2rgb(stroke_color))
    draw_pil.text(org, text, font=font, fill=bgr2rgb(color),
                  stroke_width=stroke_width, stroke_fill=bgr2rgb(stroke_color))
    return cv.cvtColor(np.array(pil_img), cv.COLOR_RGB2BGR)

def draw_panel(img, x, y, w, h, alpha=0.35, color=(0,0,0)):
    overlay = img.copy()
    cv.rectangle(overlay, (x, y), (x+w, y+h), color, thickness=-1)
    return cv.addWeighted(overlay, alpha, img, 1-alpha, 0)

# -------------- ë¯¸ëŸ¬ í‘œì‹œìš© --------------
def draw_landmarks_mirrored(frame_disp, lm_list, connections):
    mirrored = landmark_pb2.NormalizedLandmarkList(
        landmark=[landmark_pb2.NormalizedLandmark(x=1.0 - l.x, y=l.y, z=l.z) for l in lm_list]
    )
    draw.draw_landmarks(frame_disp, mirrored, connections)

# ----------------- ë©”ì¸ -----------------
def main():
    ap = argparse.ArgumentParser(description="(Lite) Webcam â†’ MediaPipe â†’ Final features CSV (Mirror+KR)")
    ap.add_argument("--artifact_path", type=str,
                default="./pd_hc_binary/best_pipeline_recall_ExtraTrees.joblib",
                help="ì €ì¥ëœ íŒŒì´í”„ë¼ì¸(.joblib) ë˜ëŠ” ë²ˆë“¤(dict) ê²½ë¡œ")
    ap.add_argument("--camera", type=int, default=0)
    ap.add_argument("--outdir", type=str, default="./outputs")
    ap.add_argument("--schema_csv", type=str, default="./severity_dataset_dropped_correlated_columns_modf.csv")
    ap.add_argument("--prep_seconds", type=int, default=5)
    ap.add_argument("--taps", type=int, default=10)
    ap.add_argument("--max_seconds", type=int, default=180)
    ap.add_argument("--tap_on_ratio", type=float, default=0.035)  # ì ‘ì´‰ ì„ê³„
    ap.add_argument("--tap_off_ratio", type=float, default=0.06)  # í•´ì œ ì„ê³„(íˆìŠ¤í…Œë¦¬ì‹œìŠ¤)
    ap.add_argument("--font", type=str, default="")
    ap.add_argument("--swap_labels_for_display", action="store_true", default=True,
                    help="ê±°ìš¸ í™”ë©´ì—ì„œ ë¼ë²¨/ì¹´ìš´íŠ¸ë¥¼ ì‚¬ìš©ì ì‹œì ìœ¼ë¡œ ìŠ¤ì™‘í•´ í‘œì‹œ(ê¸°ë³¸ ON)")
    args = ap.parse_args()

    outdir = ensure_dir(args.outdir)
    schema_cols = list(pd.read_csv(args.schema_csv, nrows=1).columns)
    tag = now_tag()
    features_fname = f"features_{tag}.csv"  # â† ìµœì¢… í”¼ì²˜ íŒŒì¼ëª…
    font_path = args.font if args.font else _auto_korean_font()

    cap = cv.VideoCapture(args.camera)
    if not cap.isOpened(): raise RuntimeError(f"ì›¹ìº ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. --camera {args.camera}")

    hands = Hands(static_image_mode=False, max_num_hands=2, 
                  model_complexity=1, # 0 â†’ ë¹ ë¦„(ë¶€ì •í™•), 1 â†’ ê· í˜•, 2 â†’ ë” ì •í™•
                  min_detection_confidence=0.6, min_tracking_confidence=0.8)  # ì¶”ì  ì•ˆì •ì„± (ì—¬ê¸° ì˜¬ë¦¬ëŠ” ê²Œ íš¨ê³¼ í¼)

    # 1) ì¤€ë¹„(ê±°ìš¸ ë¯¸ë¦¬ë³´ê¸°)
    prep_start = time.time()
    while True:
        ok, frame = cap.read()
        if not ok: cap.release(); cv.destroyAllWindows(); raise RuntimeError("ì¹´ë©”ë¼ í”„ë ˆì„ ìˆ˜ì‹  ì‹¤íŒ¨")
        h, w = frame.shape[:2]
        frame_disp = cv.flip(frame.copy(), 1)

        remain = args.prep_seconds - (time.time() - prep_start)
        if remain < 0: break

        frame_disp = put_kr(frame_disp, "ì¤€ë¹„ ì¤‘ (ê±°ìš¸ í™”ë©´)", (10, 40), font_path, 28, (0,255,255))
        frame_disp = put_kr(frame_disp, f"ì‹œì‘ê¹Œì§€: {int(np.ceil(remain))}ì´ˆ", (10, 80), font_path, 26, (0,255,255))
        frame_disp = put_kr(frame_disp, f"ëª©í‘œ: ì–‘ì† ê° {args.taps}íšŒ", (10, h-40), font_path, 26, (255,255,255))
        cv.imshow("Hand Capture (Mirror)", frame_disp)
        if cv.waitKey(1) & 0xFF == ord('q'):
            cap.release(); cv.destroyAllWindows(); return

    # 2) ì¸¡ì •(ì–‘ì† ëª¨ë‘ ëª©í‘œ ë„ë‹¬ ì‹œ ì¢…ë£Œ)
    session_landmarks = {"Left": [], "Right": []}   # ì‹¤ì œ ì† ê¸°ì¤€ìœ¼ë¡œ ì €ì¥
    last_release, count = {"Left": True, "Right": True}, {"Left": 0, "Right": 0}
    min_side, meas_start = None, time.time()

    while True:
        ok, frame = cap.read()
        if not ok: break
        h, w = frame.shape[:2]
        if min_side is None: min_side = min(w, h)
        on_th, off_th = min_side*args.tap_on_ratio, min_side*args.tap_off_ratio

        # íƒì§€: ì›ë³¸ í”„ë ˆì„(ì‹¤ì œ ì† ê¸°ì¤€)
        rgb = cv.cvtColor(frame, cv.COLOR_BGR2RGB)
        res = hands.process(rgb)

        current = {"Left": None, "Right": None}
        frame_disp = cv.flip(frame.copy(), 1)  # í‘œì‹œìš© ê±°ìš¸ í”„ë ˆì„

        if res.multi_hand_landmarks and res.multi_handedness:
            for i, hd in enumerate(res.multi_handedness):
                label = hd.classification[0].label  # 'Left'|'Right' (ì‹¤ì œ ì†)
                score = hd.classification[0].score
                if score < 0.5: continue
                lm = res.multi_hand_landmarks[i].landmark
                current[label] = lm

                # (a) ê±°ìš¸ í”„ë ˆì„ì— ëœë“œë§ˆí¬ ê·¸ë¦¬ê¸°
                draw_landmarks_mirrored(frame_disp, lm, HAND_CONNECTIONS)

                # (b) ë¼ë²¨ í‘œê¸°: ê±°ìš¸ í™”ë©´ ê¸°ì¤€ ìŠ¤ì™‘ í‘œê¸°(ì‚¬ìš©ì ì‹œì )
                if args.swap_labels_for_display:
                    disp_label = "ì˜¤ë¥¸ì†" if label == "Left" else "ì™¼ì†"
                else:
                    disp_label = "ì™¼ì†" if label == "Left" else "ì˜¤ë¥¸ì†"
                posx = 10 if (label == 'Left') else w - 210
                score_pct = int(round(score * 100))
                frame_disp = put_kr(frame_disp, f"{disp_label}({score_pct}%)", (posx, 28), font_path, 24, (0,255,0))

                # (c) íƒ­ ê°ì§€: ì›ë³¸ ì¢Œí‘œê³„ë¡œ ê³„ì‚°(ì‹¤ì œ ì† ê¸°ì¤€ ì¹´ìš´íŠ¸)
                tx, ty = int(lm[4].x*w), int(lm[4].y*h)
                ix, iy = int(lm[8].x*w), int(lm[8].y*h)
                dpx = float(np.hypot(tx-ix, ty-iy))
                touching = dpx < on_th
                if last_release[label] and touching:
                    count[label] += 1
                    last_release[label] = False
                if dpx > off_th:
                    last_release[label] = True

                # (d) ë…¸ë€ ì /ì„ : ê±°ìš¸ í”„ë ˆì„ ì¢Œí‘œë¡œ ë³€í™˜ í›„ ê·¸ë¦¬ê¸°
                mtx, mix = (w - 1 - tx), (w - 1 - ix)
                cv.circle(frame_disp, (mtx, ty), 4, (0,255,255), -1)
                cv.circle(frame_disp, (mix, iy), 4, (0,255,255), -1)
                cv.line(frame_disp, (mtx, ty), (mix, iy), (0,255,255), 2)

        session_landmarks["Left"].append(current["Left"])
        session_landmarks["Right"].append(current["Right"])

        # í•˜ë‹¨ íŒ¨ë„(ê°€ë ¤ì§€ì§€ ì•Šê²Œ ë°˜íˆ¬ëª… ë°°ê²½)
        panel_h = 78
        frame_disp = draw_panel(frame_disp, 6, h - panel_h - 6, w - 12, panel_h, alpha=0.30, color=(0,0,0))

        # ì‹¤ì œ ì¹´ìš´íŠ¸(ì¢…ë£Œ íŒë‹¨ìš©)
        elapsed = time.time() - meas_start
        lc_true = min(count["Left"],  args.taps)
        rc_true = min(count["Right"], args.taps)

        # í‘œì‹œìš© ì¹´ìš´íŠ¸(ê±°ìš¸ í™”ë©´ ì‹œì ìœ¼ë¡œ ìŠ¤ì™‘)
        if args.swap_labels_for_display:
            lc_disp, rc_disp = rc_true, lc_true
        else:
            lc_disp, rc_disp = lc_true, rc_true

        # í…ìŠ¤íŠ¸ í‘œì‹œ
        frame_disp = put_kr(frame_disp, f"ì‹œê°„: {elapsed:4.1f}ì´ˆ", (12, h - panel_h - 6 + 26),
                            font_path, 26, (255,255,255))
        frame_disp = put_kr(frame_disp, f"ì™¼ì† {lc_disp}/{args.taps}  |  ì˜¤ë¥¸ì† {rc_disp}/{args.taps}",
                            (12, h - panel_h - 6 + 56), font_path, 26, (255,255,255))
        cv.imshow("Hand Capture (Mirror)", frame_disp)

        # ì¢…ë£Œ: ì‹¤ì œ ì–‘ì† ëª¨ë‘ ëª©í‘œ ë„ë‹¬
        if (lc_true >= args.taps) and (rc_true >= args.taps): break
        if elapsed >= args.max_seconds: break
        if cv.waitKey(1) & 0xFF == ord('q'): break

    cap.release(); cv.destroyAllWindows()

    frame_size = (int(w), int(h)); total_duration = time.time() - meas_start
    write_landmarks_csv(outdir, tag, "LEFT",  session_landmarks["Left"])
    write_landmarks_csv(outdir, tag, "RIGHT", session_landmarks["Right"])

    data_by_hand = collect_timeseries(session_landmarks, frame_size, total_duration)
    rows = []
    for label in ["Left", "Right"]:
        try:
            feats = get_final_features(data_by_hand[label]); feats["hand"] = label.lower()
        except Exception as e:
            print(f"[WARN] {label} í”¼ì²˜ ê³„ì‚° ì‹¤íŒ¨: {e}"); feats = {"hand": label.lower()}
        rows.append(feats)

    df = pd.DataFrame(rows)
    df["filename"] = features_fname
    for c in schema_cols:
        if c not in df.columns:
            df[c] = np.nan
    df = df[schema_cols]

    out_path = os.path.join(outdir, features_fname)
    df.to_csv(out_path, index=False)
    print(f"[SAVED] {out_path}")

  

    ########################
    # === ëª¨ë¸ ì˜ˆì¸¡ ì¶”ê°€ ===
    ########################
    import traceback
    from joblib import load
    from sklearn.pipeline import Pipeline
    from sklearn.compose import ColumnTransformer
    from sklearn.preprocessing import OneHotEncoder

    pipe_path = args.artifact_path
    print(f"[INFO] Loading artifact: {pipe_path}")
    bundle = load(pipe_path)
    print(f"[INFO] Loaded object type: {type(bundle)}")

    # --------- ìœ í‹¸ ---------
    def find_column_transformer(pipe: Pipeline):
        if isinstance(pipe, Pipeline):
            for name, step in pipe.steps:
                if isinstance(step, ColumnTransformer):
                    return step
        return None

    def align_raw_to_expected(df_raw, expected_cols, num_cols, cat_cols):
        # ëˆ„ë½ ì»¬ëŸ¼ ì±„ìš°ê¸° (ìˆ˜ì¹˜=0.0, ë²”ì£¼='unknown')
        for c in expected_cols:
            if c not in df_raw.columns:
                if c in num_cols:
                    df_raw[c] = 0.0
                else:
                    df_raw[c] = "unknown"
        df_infer = df_raw[expected_cols].copy()

        # NaN/dtype ë³´ì •
        for c in num_cols:
            if c in df_infer.columns:
                df_infer[c] = pd.to_numeric(df_infer[c], errors="coerce").fillna(0.0)
        for c in cat_cols:
            if c in df_infer.columns:
                df_infer[c] = df_infer[c].astype("object").fillna("unknown")
        return df_infer

    def build_prefixed_frame_from_raw(df_raw, expected_prefixed_cols):
        """ì „ì²˜ë¦¬ ì—†ëŠ” ëª¨ë¸ë§Œ ì €ì¥ëœ ê²½ìš°: num__/cat__ ìŠ¤í‚¤ë§ˆë¥¼ ì›ë³¸ì—ì„œ ìƒì„±"""
        out = pd.DataFrame(index=df_raw.index)
        df_norm = df_raw.copy()
        if "hand" in df_norm.columns:
            df_norm["hand"] = df_norm["hand"].astype(str).str.lower()

        for col in expected_prefixed_cols:
            if col.startswith("num__"):
                base = col.split("num__", 1)[1]
                out[col] = pd.to_numeric(df_norm.get(base, 0.0), errors="coerce").fillna(0.0)
            elif col.startswith("cat__"):
                base = col.split("cat__", 1)[1]
                if "_" in base:
                    feat, level = base.split("_", 1)
                    val = df_norm.get(feat, "unknown")
                    val = val.astype(str).fillna("unknown")
                    out[col] = (val.str.lower() == level.lower()).astype(int)
                else:
                    out[col] = (df_norm.get(base, pd.Series(["unknown"]*len(df_norm))).astype(str) != "unknown").astype(int)
            else:
                out[col] = 0.0

        out = out.reindex(columns=expected_prefixed_cols, fill_value=0.0)
        return out

    # --------- ë²ˆë“¤ í•´ì²´: Pipeline / Dict / Model ëŒ€ì‘ ---------
    try:
        pipeline = None
        model = None
        pre = None
        selected_prefixed = None  # num__/cat__ í˜•íƒœ
        raw_features = None       # ì›ë³¸ ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸

        if isinstance(bundle, Pipeline):
            pipeline = bundle
        elif isinstance(bundle, dict):
            # ê°€ì¥ ìš°ì„ : ì™„ì„± íŒŒì´í”„ë¼ì¸ì´ ë‹´ê²¨ìˆë‹¤ë©´ ê·¸ê±¸ ì‚¬ìš©
            if "pipeline" in bundle and isinstance(bundle["pipeline"], Pipeline):
                pipeline = bundle["pipeline"]
            # ì•„ë‹ˆë©´ modelê³¼ preprocessorë¡œ íŒŒì´í”„ë¼ì¸ ì¬êµ¬ì„±
            if pipeline is None and ("model" in bundle):
                model = bundle["model"]
                pre = bundle.get("preprocessor", None)
                if pre is not None:
                    pipeline = Pipeline([("preprocessor", pre), ("classifier", model)])
            # í”¼ì²˜ ì´ë¦„ íŒíŠ¸
            selected_prefixed = bundle.get("selected_features") or bundle.get("final_selected_features")
            raw_features = bundle.get("raw_features")
        else:
            # Estimator ë‹¨ë…
            model = bundle

        # --- ì…ë ¥ ì›ë³¸ ë¡œë“œ ---
        df_raw_all = pd.read_csv(out_path)  # ë°©ê¸ˆ ì €ì¥í•œ features_*.csv
        # hand/gender ë“± ë²”ì£¼ í‘œì¤€í™”
        if "hand" in df_raw_all.columns:
            df_raw_all["hand"] = df_raw_all["hand"].astype(str).str.lower()

        # ---------- ë¶„ê¸° 1: íŒŒì´í”„ë¼ì¸ì´ ìˆëŠ” ê²½ìš° ----------
        if pipeline is not None:
            print("[INFO] Using Pipeline for inference.")
            pre_ct = find_column_transformer(pipeline)
            if pre_ct is None:
                # ë“œë¬¼ê²Œ ì „ì²˜ë¦¬ ì—†ëŠ” íŒŒì´í”„ë¼ì¸ì´ë©´ ì›ë³¸ ì „ì²´ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                df_infer = df_raw_all.copy()
            else:
                expected_cols = list(pre_ct.feature_names_in_)
                # ìˆ˜ì¹˜/ë²”ì£¼ ì»¬ëŸ¼ êµ¬ë¶„
                num_cols, cat_cols = [], []
                for name, trans, cols in pre_ct.transformers_:
                    if name == "num":
                        num_cols = list(cols)
                    elif name == "cat":
                        cat_cols = list(cols)

                # raw_features íŒíŠ¸ê°€ ìˆìœ¼ë©´ ê·¸ ì§‘í•©ì„ ìš°ì„  ë§ì¶”ê³ , ë‚˜ë¨¸ì§€ expectedë¥¼ ë³´ì •
                if raw_features is not None:
                    for c in raw_features:
                        if c not in df_raw_all.columns:
                            df_raw_all[c] = np.nan
                df_infer = align_raw_to_expected(df_raw_all, expected_cols, num_cols, cat_cols)

            # ì˜ˆì¸¡
            y_pred = pipeline.predict(df_infer)
            y_prob = (
                pipeline.predict_proba(df_infer)[:, 1]
                if hasattr(pipeline, "predict_proba") else
                np.full(len(df_infer), np.nan)
            )

        # ---------- ë¶„ê¸° 2: ëª¨ë¸ë§Œ ìˆê³ , selected_features(ì ‘ë‘ì‚¬) ì œê³µ ----------
        elif (model is not None) and (selected_prefixed is not None):
            print("[INFO] Using bare model + prefixed features (selected_features) for inference.")
            df_pref = build_prefixed_frame_from_raw(df_raw_all, selected_prefixed)
            y_pred = model.predict(df_pref)
            y_prob = (
                model.predict_proba(df_pref)[:, 1]
                if hasattr(model, "predict_proba") else
                np.full(len(df_pref), np.nan)
            )

        # ---------- ë¶„ê¸° 3: ëª¨ë¸ë§Œ ìˆê³ , feature_names_in_ ì œê³µ ----------
        elif (model is not None) and hasattr(model, "feature_names_in_"):
            print("[INFO] Using bare model + feature_names_in_ for inference.")
            expected_prefixed = list(model.feature_names_in_)
            df_pref = build_prefixed_frame_from_raw(df_raw_all, expected_prefixed)
            y_pred = model.predict(df_pref)
            y_prob = (
                model.predict_proba(df_pref)[:, 1]
                if hasattr(model, "predict_proba") else
                np.full(len(df_pref), np.nan)
            )

        else:
            raise RuntimeError(
                "ì•„í‹°íŒ©íŠ¸ë¥¼ í•´ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (pipeline/model/selected_features/feature_names_in_ ì¤‘ í•˜ë‚˜ê°€ í•„ìš”)"
            )

        # --- ê²°ê³¼ ì €ì¥/ì¶œë ¥ ---
        df_out = df_raw_all.copy()
        df_out["prediction"] = y_pred
        df_out["probability"] = y_prob
        for _, row in df_out.iterrows():
            label = "í™˜ì(PD)" if row["prediction"] == 1 else "ì •ìƒ(HC)"
            print(f"[RESULT] {row.get('hand','?')}: {label} (ìœ„í—˜ë„={row['probability']:.2f})")

        pred_path = out_path.replace("features_", "predictions_")
        df_out.to_csv(pred_path, index=False)
        print(f"[INFO] Saved predictions to {pred_path}")

    except Exception as e:
        print("[ERROR] Inference failed.")
        traceback.print_exc()
        print("=== DEBUG HINTS ===")
        print(f"- Artifact path           : {pipe_path}")
        print(f"- Is Pipeline?            : {isinstance(bundle, Pipeline)}")
        if isinstance(bundle, dict):
            print(f"- Dict keys               : {list(bundle.keys())}")


if __name__ == "__main__":
    main()




